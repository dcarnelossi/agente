from database import PostgresDB
from langchain.schema import AIMessage, HumanMessage
from langchain_community.agent_toolkits import SQLDatabaseToolkit
from langchain_community.tools.sql_database.tool import QuerySQLCheckerTool
from llm import model
from prompt import format_answer_prompt, get_classification_prompt, sql_prompt


class EcommerceAgent:
    def __init__(self):
        self.db = PostgresDB()
        self.toolkit = SQLDatabaseToolkit(db=self.db.db, llm=model)
        self.query_checker = QuerySQLCheckerTool(db=self.db.db, llm=model)  # üîπ Instancia o validador SQL

    def classify_query(self, state: dict) -> dict:
        """
        Classifica a consulta e adiciona uma resposta ao usu√°rio.
        """
        user_query = state["messages"][-1].content  # √öltima mensagem do usu√°rio
        classification_prompt = get_classification_prompt(user_query)

        response = model.invoke([HumanMessage(content=classification_prompt)]).content.strip()
        is_valid = response.upper() == "SIM"

        new_message = AIMessage(
            content="‚úÖ Essa √© uma pergunta v√°lida sobre e-commerce. Vou process√°-la."
            if is_valid
            else "‚ùå Desculpe, s√≥ posso responder perguntas sobre vendas, produtos ou faturamento."
        )

        # üîπ Atualiza o estado sem sobrescrever mensagens
        state["messages"].append(new_message)
        state["user_query"] = user_query

        return state | {"is_valid_query": is_valid}

    def analyze_tables(self, state: dict) -> dict:
        """
        Obt√©m informa√ß√µes das tabelas e adiciona ao estado.
        """
        state["messages"].append(AIMessage(content="üîç Obtendo informa√ß√µes das tabelas relevantes..."))

        tools = self.toolkit.get_tools()
        get_schema_tool = next(tool for tool in tools if tool.name == "sql_db_schema")

        tables = ["orders_ia", "orders_items_ia"]
        table_schemas = {}

        for table in tables:
            try:
                full_info = get_schema_tool.invoke(table)
                table_schemas[table] = full_info
            except Exception:
                table_schemas[table] = "Erro ao obter esquema"

        return state | {"table_schemas": table_schemas}

    def generate_sql(self, state: dict) -> dict:
        """
        Gera uma consulta SQL para responder √† pergunta do usu√°rio.
        Se houver erro, adiciona uma mensagem no chat pedindo a corre√ß√£o.
        """
        user_query = state["user_query"]
        table_schemas = state.get("table_schemas", {})
        query_error = state.get("query_error")  # Verifica se h√° erro anterior

        if not table_schemas:
            return state | {"sql_query": "Erro: Nenhuma informa√ß√£o de tabela dispon√≠vel."}

        # üîπ Formata o contexto do banco de dados
        schema_context = "\n".join([f"Table {table}: {schema}" for table, schema in table_schemas.items()])

        # üîπ Se for a primeira tentativa, adicionamos o prompt original
        if not query_error:
            sql_prompt_text = sql_prompt(schema_context, user_query)
            state["messages"].append(HumanMessage(content=sql_prompt_text))
        else:
            # üîπ Se houve erro, adicionamos uma nova mensagem pedindo corre√ß√£o
            state["messages"].append(
                HumanMessage(content=f"Sua query retornou com esse erro: {query_error}. Por favor, corrija.")
            )

        # üîπ Invocamos o LLM passando o hist√≥rico de mensagens
        llm_response = model.invoke(state["messages"])

        sql_query = llm_response.content.strip()

        if not sql_query.lower().startswith("select"):
            return state | {"sql_query": f"Erro: A query gerada n√£o √© v√°lida.\nQuery: {sql_query}"}

        # üîπ Adicionamos a resposta do LLM no hist√≥rico
        state["messages"].append(AIMessage(content=sql_query))

        return state | {
            "sql_query": sql_query,
            "query_error": None,  # üîπ Resetamos o erro ap√≥s a corre√ß√£o
            "retry_generate_sql": False,  # üîπ Resetamos a flag para evitar loops infinitos
        }

    def validate_sql(self, state: dict) -> dict:
        """
        Valida a query SQL antes da execu√ß√£o usando `QuerySQLCheckerTool`.
        """
        state["messages"].append(AIMessage(content="üîé Validando a query SQL..."))

        query = state.get("sql_query", "")
        validation_result = self.query_checker.run(query)  # üîπ Valida a SQL

        # üîπ Se a valida√ß√£o encontrar erro, retorna para gerar uma nova query
        if "ERROR:" in validation_result or "SQL state" in validation_result:
            state["messages"].append(AIMessage(content=f"‚ùå Erro na valida√ß√£o da query: {validation_result}"))
            return state | {"sql_error": validation_result, "retry_generate_sql": True}

        state["messages"].append(AIMessage(content="‚úÖ Query SQL validada com sucesso!"))
        return state | {"sql_error": None}  # üîπ Reseta qualquer erro anterior

    def execute_sql(self, state: dict) -> dict:
        """
        Executa a consulta SQL no banco de dados e retorna os resultados.
        Se houver erro, volta para o LLM como uma nova mensagem de chat pedindo corre√ß√£o.
        """
        state["messages"].append(AIMessage(content="‚è≥ Executando a query no banco de dados..."))

        query = state.get("sql_query", "")
        result = self.db.run_no_throw(query)  # Retorna sempre uma string

        # üîπ Se a resposta come√ßa com "ERROR:", consideramos uma falha na execu√ß√£o
        if result.startswith("ERROR:") or "SQL state:" in result:
            # üîπ Ao inv√©s de sobrescrever o prompt, adicionamos uma nova mensagem no chat
            state["messages"].append(
                HumanMessage(content=f"Sua query retornou com esse erro: {result}. Por favor, corrija-a.")
            )

            return state | {
                "query_error": result,
                "retry_generate_sql": True,  # üîπ Apenas ativamos se houver erro
            }

        state["messages"].append(AIMessage(content="‚úÖ Consulta SQL executada com sucesso."))

        return state | {
            "query_response": result,
            "retry_generate_sql": False,  # üîπ Resetamos para evitar loops
        }

    def generate_answer(self, state: dict) -> dict:
        """
        Gera a resposta final para o usu√°rio baseada na consulta SQL e nos dados retornados.
        """
        state["messages"].append(AIMessage(content="‚úÖ Processando os resultados da consulta..."))

        sql_query = state.get("sql_query", "")
        query_response = state.get("query_response", [])

        if not query_response or "Erro" in query_response[0]:
            return state | {"final_answer": "‚ùå Desculpe, n√£o foi poss√≠vel obter uma resposta."}

        answer_prompt = format_answer_prompt(state["user_query"], sql_query, query_response)
        final_answer = model.invoke([HumanMessage(content=answer_prompt)]).content.strip()

        state["messages"].append(AIMessage(content=final_answer))

        return state | {"final_answer": final_answer}
